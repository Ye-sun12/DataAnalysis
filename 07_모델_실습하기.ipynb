{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coin Machine Learning Algorithm Practice\n",
    "***\n",
    "\n",
    "### Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:48:09.268500Z",
     "start_time": "2021-02-13T02:48:09.255502Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_feature  = np.array([[10], [8], [5], [3], [1]])  # 공부시간\n",
    "# 2차원 array로 만든 이유\n",
    "# 현재는 feature를 단순화 하기위해 1가지 변수(공부시간)만 들어가 있지만, \n",
    "# 실제로는 여러 가지 feature들이 들어갈 수 있기 때문에 2차원으로 만들어준다.\n",
    "# 1차원 index = i 번째 데이터에 접근, 2차원 index = i번째 feature에 접근\n",
    "train_label_regression = np.array([100, 80, 50, 30, 10]) # 성적\n",
    "train_label_binary_classification = np.array([1, 1, 1, 0, 0]) # Pass/Non Pass\n",
    "train_label_multi_classification = np.array([1, 2, 3, 0, 0]) # A,B,C,F,F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy 쓰는 이유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T00:26:40.028854Z",
     "start_time": "2021-02-13T00:26:40.000726Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-62ecae1ce89f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# python list 사용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'list'"
     ]
    }
   ],
   "source": [
    "# python list 사용\n",
    "[1,2,3] * [1,2,3] # Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T00:26:40.153753Z",
     "start_time": "2021-02-13T00:26:40.137753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np 사용\n",
    "# 연산이 편리함\n",
    "np.array([1,2,3])*np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T00:26:57.668926Z",
     "start_time": "2021-02-13T00:26:57.654895Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# data\n",
    "x_train = train_feature\n",
    "y_train = train_label_regression\n",
    "x_test = np.array([[6]])\n",
    "\n",
    "W = random.uniform(0,20)\n",
    "\n",
    "size = len(x_train)\n",
    "cost = 0\n",
    "gradient = 0\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientDescentOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T00:26:58.794137Z",
     "start_time": "2021-02-13T00:26:58.777137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt= 0, cost=    8.2198, descent= 10.27358\n",
      "cnt= 1, cost=    4.6229, descent= 10.12852\n",
      "cnt= 2, cost=    1.5820, descent= 10.04836\n",
      "cnt= 3, cost=    0.4095, descent= 10.01308\n",
      "cnt= 4, cost=    0.0887, descent= 10.00082\n",
      "cnt= 5, cost=    0.0178, descent= 9.99804\n",
      "cnt= 6, cost=    0.0037, descent= 9.99826\n",
      "cnt= 7, cost=    0.0009, descent= 9.99900\n",
      "cnt= 8, cost=    0.0002, descent= 9.99955\n",
      "cnt= 9, cost=    0.0001, descent= 9.99984\n",
      "cnt=10, cost=    0.0000, descent= 9.99996\n",
      "cnt=11, cost=    0.0000, descent= 10.00000\n",
      "cnt=12, cost=    0.0000, descent= 10.00001\n",
      "cnt=13, cost=    0.0000, descent= 10.00001\n",
      "cnt=14, cost=    0.0000, descent= 10.00000\n",
      "cnt=15, cost=    0.0000, descent= 10.00000\n",
      "cnt=16, cost=    0.0000, descent= 10.00000\n",
      "cnt=17, cost=    0.0000, descent= 10.00000\n",
      "cnt=18, cost=    0.0000, descent= 10.00000\n",
      "cnt=19, cost=    0.0000, descent= 10.00000\n"
     ]
    }
   ],
   "source": [
    "for cnt in range(20):\n",
    "    for i in range(size):\n",
    "        hypothesis = W*x_train[i]\n",
    "        cost += np.square(hypothesis-y_train[i]) # 차이값 제곱해서 더하기\n",
    "        gradient += (hypothesis - y_train[i])*x_train[i]\n",
    "    cost = cost/size #  평균구하기\n",
    "    gradient = gradient/size\n",
    "    descent = W - learning_rate * gradient\n",
    "#     if cnt % 10 == 0 :\n",
    "    print(f'cnt={cnt:2d}, cost={float(cost):10.4f}, descent= {float(descent):.5f}')\n",
    "    W = descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T00:27:08.185540Z",
     "start_time": "2021-02-13T00:27:08.173538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59.9999998]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측이라는 것은 결국 잘 학습된 모델()\n",
    "prediction = W * x_test # 공부시간이 6시간일 때 점수 예측\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi variable Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:28:17.999987Z",
     "start_time": "2021-02-13T02:28:17.911953Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "cnt= 0, cost=  315.1448\n",
      "w1 = 0.278, w2= 0.548\n",
      "----------------------------------------------\n",
      "cnt=200, cost=    0.6734\n",
      "w1 = 0.418, w2= 0.582\n",
      "----------------------------------------------\n",
      "cnt=400, cost=    0.2477\n",
      "w1 = 0.450, w2= 0.550\n",
      "----------------------------------------------\n",
      "cnt=600, cost=    0.0911\n",
      "w1 = 0.470, w2= 0.530\n",
      "----------------------------------------------\n",
      "cnt=800, cost=    0.0335\n",
      "w1 = 0.482, w2= 0.518\n",
      "----------------------------------------------\n",
      "cnt=1000, cost=    0.0123\n",
      "w1 = 0.489, w2= 0.511\n",
      "----------------------------------------------\n",
      "cnt=1200, cost=    0.0045\n",
      "w1 = 0.493, w2= 0.507\n",
      "----------------------------------------------\n",
      "cnt=1400, cost=    0.0017\n",
      "w1 = 0.496, w2= 0.504\n",
      "----------------------------------------------\n",
      "cnt=1600, cost=    0.0006\n",
      "w1 = 0.498, w2= 0.502\n",
      "----------------------------------------------\n",
      "cnt=1800, cost=    0.0002\n",
      "w1 = 0.498, w2= 0.501\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# (x1+x2)/2 = y 인 식에 대한 linear Regerssion\n",
    "x_train = np.array([[100,90], [80, 90], [45, 55], [30, 20], [10, 0]])\n",
    "y_train = np.array([[95], [85], [50], [25], [5]])\n",
    "size = x_train.shape[0]\n",
    "W = np.array([random.uniform(0,1),random.uniform(0,1)])\n",
    "learning_rate = 5e-5\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "for cnt in range(2000):\n",
    "    hypothesis = W*x_train\n",
    "    cost = np.mean(np.square(np.sum(hypothesis, axis=1).reshape(size,1)-y_train)) # 차이값 제곱해서 더하기\n",
    "    gradient = np.mean((np.sum(hypothesis, axis=1).reshape(size,1)-y_train)*x_train, axis=0)\n",
    "    W = W - learning_rate * gradient\n",
    "    if cnt % 200 == 0:\n",
    "        print(f'cnt={cnt:2d}, cost={float(cost):10.4f}')\n",
    "        print(f'w1 = {float(W[0]):.3f}, w2= {float(W[1]):.3f}')\n",
    "        print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:33:49.541148Z",
     "start_time": "2021-02-13T02:33:49.530176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pridiction = 30.036\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array([[10,50]])\n",
    "prediction = np.sum(W*x_test)\n",
    "print(f'pridiction = {prediction:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:33:54.426555Z",
     "start_time": "2021-02-13T02:33:54.421553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lr_model = linear_model.LinearRegression()\n",
    "lr_model.fit(x_train, y_train)\n",
    "lr_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:35:14.635013Z",
     "start_time": "2021-02-13T02:35:14.628019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 우리가 만든 모델의 테스트 데이터 사용\n",
    "# x_test = np.array([[10,50]])\n",
    "lr_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "- linear regression 모델을 logistic function을 통해서 binarry classification으로 변경시켜줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:49:21.030237Z",
     "start_time": "2021-02-13T02:49:21.020241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_feature\n",
    "y_train = train_label_binary_classification\n",
    "x_test = np.array([[3]])\n",
    "\n",
    "logistic_regression_model = linear_model.LogisticRegression()\n",
    "logistic_regression_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:49:21.388535Z",
     "start_time": "2021-02-13T02:49:21.373464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1시간 공부시 합격여부 = 불합격\n",
      "2시간 공부시 합격여부 = 불합격\n",
      "3시간 공부시 합격여부 = 불합격\n",
      "4시간 공부시 합격여부 = 불합격\n",
      "5시간 공부시 합격여부 = 합격\n",
      "6시간 공부시 합격여부 = 합격\n",
      "7시간 공부시 합격여부 = 합격\n",
      "8시간 공부시 합격여부 = 합격\n",
      "9시간 공부시 합격여부 = 합격\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    prediction = logistic_regression_model.predict(np.array([[i]]))\n",
    "    result = \"합격\" if prediction == 1 else '불합격'\n",
    "    print(f'{i}시간 공부시 합격여부 = {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN(k - Nearest Neighbors)\n",
    "- k개의 인접한 점의 분류 결과를 보고 새로운 점의 분류 결과를 예측함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T02:54:40.688467Z",
     "start_time": "2021-02-13T02:54:40.683431Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = np.array([\n",
    "    [9, 2], # kick count, kiss count\n",
    "    [8, 4], # kick count, kiss count\n",
    "    [5, 0], # kick count, kiss count\n",
    "    [4, 0], # kick count, kiss count\n",
    "    [5, 2], # kick count, kiss count\n",
    "    [2, 7], # kick count, kiss count\n",
    "    [4, 8], # kick count, kiss count\n",
    "    [3, 9], # kick count, kiss count\n",
    "    [0, 9], # kick count, kiss count\n",
    "    [1, 6], # kick count, kiss count\n",
    "])\n",
    "# y_train = np.array([[1],[1],[1],[1],[1],[0],[0],[0],[0],[0]])\n",
    "y_train = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T03:05:15.462381Z",
     "start_time": "2021-02-13T03:05:15.443378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=3) # n_neighbors를 통해 k값을 조절 가능\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T03:05:15.943692Z",
     "start_time": "2021-02-13T03:05:15.925729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "kick = 4, kiss = 2일 때 예측결과 = 액션영화\n",
      "----------------------------------------------------------------\n",
      "kick = 6, kiss = 6일 때 예측결과 = 로맨스영화\n",
      "----------------------------------------------------------------\n",
      "kick = 1, kiss = 9일 때 예측결과 = 로맨스영화\n",
      "----------------------------------------------------------------\n",
      "kick = 9, kiss = 7일 때 예측결과 = 액션영화\n",
      "----------------------------------------------------------------\n",
      "kick = 3, kiss = 7일 때 예측결과 = 로맨스영화\n",
      "----------------------------------------------------------------\n",
      "kick = 4, kiss = 2일 때 예측결과 = 액션영화\n",
      "----------------------------------------------------------------\n",
      "kick = 2, kiss = 2일 때 예측결과 = 액션영화\n",
      "----------------------------------------------------------------\n",
      "kick = 7, kiss = 6일 때 예측결과 = 액션영화\n",
      "----------------------------------------------------------------\n",
      "kick = 2, kiss = 4일 때 예측결과 = 로맨스영화\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    kick_count = random.uniform(1,9)\n",
    "    kiss_count = random.uniform(1,9)\n",
    "    prediction = clf.predict(np.array([[kick_count, kiss_count]]))\n",
    "    result = \"액션영화\" if prediction == 1 else '로맨스영화'\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(f'kick = {kick_count:.0f}, kiss = {kiss_count:.0f}일 때 예측결과 = {result}')\n",
    "print('----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree(의사 결정 나무)\n",
    "- 트리 구조의 분류기를 만들어서 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T03:07:25.822525Z",
     "start_time": "2021-02-13T03:07:25.808549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "x_train = train_feature\n",
    "y_train = train_label_multi_classification\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T03:09:55.433730Z",
     "start_time": "2021-02-13T03:09:55.419699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1시간 공부시 학점 예측 = F\n",
      " 2시간 공부시 학점 예측 = F\n",
      " 3시간 공부시 학점 예측 = F\n",
      " 4시간 공부시 학점 예측 = F\n",
      " 5시간 공부시 학점 예측 = C\n",
      " 6시간 공부시 학점 예측 = C\n",
      " 7시간 공부시 학점 예측 = B\n",
      " 8시간 공부시 학점 예측 = B\n",
      " 9시간 공부시 학점 예측 = B\n",
      "10시간 공부시 학점 예측 = A\n",
      "11시간 공부시 학점 예측 = A\n",
      "12시간 공부시 학점 예측 = A\n",
      "13시간 공부시 학점 예측 = A\n",
      "14시간 공부시 학점 예측 = A\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,15):\n",
    "    prediction = clf.predict(np.array([[i]]))\n",
    "    result = chr(prediction+64) if prediction != 0 else 'F'\n",
    "    print(f'{i:2d}시간 공부시 학점 예측 = {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (과제) 위 구현된 모델을 참고하여 아래의 3가지 모델에 대해서 자신이 간단히 조사하여<br>markdown을 작성하고 간단한 예제를 활용하여 예측 모델 구현\n",
    " - sklearn 공식 홈페이지 (https://scikit-learn.org/stable/index.html)\n",
    " - 데이터 셋은 자유롭게 가져오거나 본인이 창작하여 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "여러 개의 의사결정나무를 만들고 투표를 통해 다수결로 결과를 결정한다.\n",
    "랜덤 포레스트는 배깅 기법 중 하나이다.\n",
    "배깅 기법은 훈련세트를 여러 개의 샘플로 만들고 알고리즘마다 다른 훈련세트를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "x_train = train_feature\n",
    "y_train = train_label_multi_classification\n",
    "clfR = RandomForestClassifier(n_estimators=5)\n",
    "clfR = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1시간 공부시 학점 예측 = F\n",
      " 2시간 공부시 학점 예측 = F\n",
      " 3시간 공부시 학점 예측 = F\n",
      " 4시간 공부시 학점 예측 = F\n",
      " 5시간 공부시 학점 예측 = C\n",
      " 6시간 공부시 학점 예측 = C\n",
      " 7시간 공부시 학점 예측 = B\n",
      " 8시간 공부시 학점 예측 = B\n",
      " 9시간 공부시 학점 예측 = B\n",
      "10시간 공부시 학점 예측 = A\n",
      "11시간 공부시 학점 예측 = A\n",
      "12시간 공부시 학점 예측 = A\n",
      "13시간 공부시 학점 예측 = A\n",
      "14시간 공부시 학점 예측 = A\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,15):\n",
    "    prediction = clfR.predict(np.array([[i]]))\n",
    "    result = chr(prediction+64) if prediction != 0 else 'F'\n",
    "    print(f'{i:2d}시간 공부시 학점 예측 = {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes algorithm\n",
    "P(A|B) = P(B|A)P(A)/P(B)\n",
    "스팸필터 및 키워드 검색을 활용한 문서분류에 사용된다.\n",
    "데이터를 분류할 떄 데이터 셋의 모든 특징들이 독립적이고 동등하다고 가정하고 데이터를 분류한다.\n",
    "적은 학습 데이ㅓ로도 잘 수행된다.\n",
    "메모리 사용량이 적고 성능이 빠르다.\n",
    "각 특징들이 독립적이지 않을 경우, 오류가 발생할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "x_train = train_feature\n",
    "y_train = train_label_binary_classification\n",
    "x_test = np.array([[3]])\n",
    "\n",
    "logistic_regression_model = linear_model.LogisticRegression()\n",
    "logistic_regression_model.fit(x_train,y_train)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1시간 공부시 합격여부 = 불합격\n",
      "2시간 공부시 합격여부 = 불합격\n",
      "3시간 공부시 합격여부 = 불합격\n",
      "4시간 공부시 합격여부 = 합격\n",
      "5시간 공부시 합격여부 = 합격\n",
      "6시간 공부시 합격여부 = 합격\n",
      "7시간 공부시 합격여부 = 합격\n",
      "8시간 공부시 합격여부 = 합격\n",
      "9시간 공부시 합격여부 = 합격\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    prediction = gnb.predict(np.array([[i]]))\n",
    "    result = \"합격\" if prediction == 1 else '불합격'\n",
    "    print(f'{i}시간 공부시 합격여부 = {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM(Support Vector Meachine)\n",
    "서포트 벡터 머신은 데이터를 분류할 수 있는 선을 찾는다.\n",
    "서포트 벡터 머신은 최적화된 선을 찾기 위해 A그룹과 B그룹의 가장 바깥쪽에 있는 데이터 간의 거리가 가장 멀리 떨어진 직선을 찾는다.\n",
    "선형 서포트 벡터 머신은 초평면을 기준으로 객체 간에 마진을 최대화 되도록 분류하는 모델이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "x_train = train_feature\n",
    "y_train = train_label_multi_classification\n",
    "clfS = svm.SVC()\n",
    "clfS = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1시간 공부시 학점 예측 = F\n",
      " 2시간 공부시 학점 예측 = F\n",
      " 3시간 공부시 학점 예측 = F\n",
      " 4시간 공부시 학점 예측 = F\n",
      " 5시간 공부시 학점 예측 = C\n",
      " 6시간 공부시 학점 예측 = C\n",
      " 7시간 공부시 학점 예측 = B\n",
      " 8시간 공부시 학점 예측 = B\n",
      " 9시간 공부시 학점 예측 = B\n",
      "10시간 공부시 학점 예측 = A\n",
      "11시간 공부시 학점 예측 = A\n",
      "12시간 공부시 학점 예측 = A\n",
      "13시간 공부시 학점 예측 = A\n",
      "14시간 공부시 학점 예측 = A\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,15):\n",
    "    prediction = clfS.predict(np.array([[i]]))\n",
    "    result = chr(prediction+64) if prediction != 0 else 'F'\n",
    "    print(f'{i:2d}시간 공부시 학점 예측 = {result}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
